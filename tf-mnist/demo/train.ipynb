{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configure model options\n",
    "TF_DATA_DIR = os.getenv(\"TF_DATA_DIR\", \"/home/jovyan/work/data\")\n",
    "TF_MODEL_DIR = os.getenv(\"TF_MODEL_DIR\", \"/home/jovyan/work/model\")\n",
    "TF_EXPORT_DIR = os.getenv(\"TF_EXPORT_DIR\", \"mnist/\")\n",
    "TF_MODEL_TYPE = os.getenv(\"TF_MODEL_TYPE\", \"CNN\")\n",
    "TF_TRAIN_STEPS = int(os.getenv(\"TF_TRAIN_STEPS\", 200))\n",
    "TF_BATCH_SIZE = int(os.getenv(\"TF_BATCH_SIZE\", 100))\n",
    "TF_LEARNING_RATE = float(os.getenv(\"TF_LEARNING_RATE\", 0.01))\n",
    "\n",
    "N_DIGITS = 10  # Number of digits.\n",
    "X_FEATURE = 'x'  # Name of the input feature.\n",
    "\n",
    "\n",
    "def conv_model(features, labels, mode):\n",
    "  \"\"\"2-layer convolution model.\"\"\"\n",
    "  # Reshape feature to 4d tensor with 2nd and 3rd dimensions being\n",
    "  # image width and height final dimension being the number of color channels.\n",
    "  feature = tf.reshape(features[X_FEATURE], [-1, 28, 28, 1])\n",
    "\n",
    "  # First conv layer will compute 32 features for each 5x5 patch\n",
    "  with tf.variable_scope('conv_layer1'):\n",
    "    h_conv1 = tf.layers.conv2d(\n",
    "        feature,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "    h_pool1 = tf.layers.max_pooling2d(\n",
    "        h_conv1, pool_size=2, strides=2, padding='same')\n",
    "\n",
    "  # Second conv layer will compute 64 features for each 5x5 patch.\n",
    "  with tf.variable_scope('conv_layer2'):\n",
    "    h_conv2 = tf.layers.conv2d(\n",
    "        h_pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)\n",
    "    h_pool2 = tf.layers.max_pooling2d(\n",
    "        h_conv2, pool_size=2, strides=2, padding='same')\n",
    "    # reshape tensor into a batch of vectors\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Densely connected layer with 1024 neurons.\n",
    "  h_fc1 = tf.layers.dense(h_pool2_flat, 1024, activation=tf.nn.relu)\n",
    "  h_fc1 = tf.layers.dropout(\n",
    "      h_fc1,\n",
    "      rate=0.5,\n",
    "      training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "  # Compute logits (1 per class) and compute loss.\n",
    "  logits = tf.layers.dense(h_fc1, N_DIGITS, activation=None)\n",
    "  predict = tf.nn.softmax(logits)\n",
    "  classes = tf.cast(tf.argmax(predict, 1), tf.uint8)\n",
    "\n",
    "  # Compute predictions.\n",
    "  predicted_classes = tf.argmax(logits, 1)\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'class': predicted_classes,\n",
    "        'prob': tf.nn.softmax(logits)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions,\n",
    "        export_outputs={'classes':\n",
    "                        tf.estimator.export.PredictOutput({\"predictions\": predict,\n",
    "                                                           \"classes\": classes})})\n",
    "\n",
    "  # Compute loss.\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Create training op.\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(\n",
    "        learning_rate=TF_LEARNING_RATE)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Compute evaluation metrics.\n",
    "  eval_metric_ops = {\n",
    "      'accuracy': tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predicted_classes)\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def cnn_serving_input_receiver_fn():\n",
    "  inputs = {X_FEATURE: tf.placeholder(tf.float32, [None, 28, 28])}\n",
    "  return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def linear_serving_input_receiver_fn():\n",
    "  inputs = {X_FEATURE: tf.placeholder(tf.float32, (784,))}\n",
    "  return tf.estimator.export.ServingInputReceiver(inputs, inputs)\n",
    "\n",
    "\n",
    "def main(): # pylint: disable=unused-argument\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "  # Download and load MNIST dataset.\n",
    "  mnist = tf.contrib.learn.datasets.DATASETS['mnist'](TF_DATA_DIR)\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={X_FEATURE: mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      batch_size=TF_BATCH_SIZE,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={X_FEATURE: mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  if TF_MODEL_TYPE == \"LINEAR\":\n",
    "    # Linear classifier.\n",
    "    feature_columns = [\n",
    "        tf.feature_column.numeric_column(\n",
    "            X_FEATURE, shape=mnist.train.images.shape[1:])]\n",
    "\n",
    "    classifier = tf.estimator.LinearClassifier(\n",
    "        feature_columns=feature_columns, n_classes=N_DIGITS, model_dir=TF_MODEL_DIR)\n",
    "    classifier.train(input_fn=train_input_fn, steps=TF_TRAIN_STEPS)\n",
    "    scores = classifier.evaluate(input_fn=test_input_fn)\n",
    "    print('Accuracy (LinearClassifier): {0:f}'.format(scores['accuracy']))\n",
    "    # FIXME This doesn't seem to work. sticking to CNN for the example for now.\n",
    "    classifier.export_savedmodel(\n",
    "        TF_EXPORT_DIR, linear_serving_input_receiver_fn)\n",
    "  elif TF_MODEL_TYPE == \"CNN\":\n",
    "    # Convolutional network\n",
    "    training_config = tf.estimator.RunConfig(\n",
    "        model_dir=TF_MODEL_DIR, save_summary_steps=100, save_checkpoints_steps=1000)\n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn=conv_model, model_dir=TF_MODEL_DIR, config=training_config)\n",
    "    export_final = tf.estimator.FinalExporter(\n",
    "        TF_EXPORT_DIR, serving_input_receiver_fn=cnn_serving_input_receiver_fn)\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn, max_steps=TF_TRAIN_STEPS)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=test_input_fn,\n",
    "                                      steps=1,\n",
    "                                      exporters=export_final,\n",
    "                                      throttle_secs=1,\n",
    "                                      start_delay_secs=1)\n",
    "    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n",
    "  else:\n",
    "    print(\"No such model type: %s\" % TF_MODEL_TYPE)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
